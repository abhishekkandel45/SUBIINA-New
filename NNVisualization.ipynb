{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(256)\n",
        "        self.conv2 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(512)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(512)\n",
        "        self.conv4 = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(1024)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(1024)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(1024, 1024)\n",
        "        self.bn6 = nn.BatchNorm1d(1024)\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.bn7 = nn.BatchNorm1d(512)\n",
        "        self.dropout5 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.bn8 = nn.BatchNorm1d(256)\n",
        "        self.dropout6 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc4 = nn.Linear(256, 128)\n",
        "        self.bn9 = nn.BatchNorm1d(128)\n",
        "        self.dropout7 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc5 = nn.Linear(128, 64)\n",
        "        self.bn10 = nn.BatchNorm1d(64)\n",
        "        self.dropout8 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc6 = nn.Linear(64, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = F.relu(self.bn6(self.fc1(x)))\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = F.relu(self.bn7(self.fc2(x)))\n",
        "        x = self.dropout5(x)\n",
        "\n",
        "        x = F.relu(self.bn8(self.fc3(x)))\n",
        "        x = self.dropout6(x)\n",
        "\n",
        "        x = F.relu(self.bn9(self.fc4(x)))\n",
        "        x = self.dropout7(x)\n",
        "\n",
        "        x = F.relu(self.bn10(self.fc5(x)))\n",
        "        x = self.dropout8(x)\n",
        "\n",
        "        x = self.fc6(x)\n",
        "\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "# Instantiate the model\n",
        "model = ConvNet()\n"
      ],
      "metadata": {
        "id": "sBUDQxdjOri3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "Qk4cL01QQJSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchviz import make_dot\n",
        "\n",
        "# Instantiate the model\n",
        "model = ConvNet()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Create a dummy input tensor with the correct dimensions\n",
        "dummy_input = torch.randn(1, 1, 13, 9)  # Assuming batch size of 1, 1 channel, 13 height, 9 width\n",
        "\n",
        "# Pass the dummy input through the model\n",
        "output = model(dummy_input)\n",
        "\n",
        "# Visualize the model\n",
        "dot = make_dot(output, params=dict(model.named_parameters()), show_attrs=True, show_saved=True)\n",
        "dot.render(\"convnet_visualization\", format=\"png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rCDqpDZtOq95",
        "outputId": "051df043-9315-43cd-b672-6d6262b0d130"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'convnet_visualization.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RecurrentModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RecurrentModel, self).__init__()\n",
        "\n",
        "        # Define LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size=9, hidden_size=512, batch_first=True, num_layers=1, dropout=0.7)\n",
        "        self.lstm2 = nn.LSTM(input_size=512, hidden_size=512, batch_first=True, num_layers=1, dropout=0.7)\n",
        "        self.lstm3 = nn.LSTM(input_size=512, hidden_size=512, batch_first=True, num_layers=1, dropout=0.7)\n",
        "\n",
        "        # Define TimeDistributed layers\n",
        "        self.time_distributed1 = nn.Linear(512, 128)\n",
        "        self.time_distributed2 = nn.Linear(128, 64)\n",
        "        self.time_distributed3 = nn.Linear(64, 32)\n",
        "\n",
        "        # Flatten layer\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Define Dense layer\n",
        "        self.dense = nn.Linear(32 * 13, 256)\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.Linear(256, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM layers\n",
        "        x, _ = self.lstm1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "        x, _ = self.lstm3(x)\n",
        "\n",
        "        # TimeDistributed layers\n",
        "        x = self.time_distributed1(x)\n",
        "        x = self.time_distributed2(x)\n",
        "        x = self.time_distributed3(x)\n",
        "\n",
        "        # Flatten layer\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # Dense layer\n",
        "        x = self.dense(x)\n",
        "\n",
        "        # Output layer\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "_GA0las-Ouux"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming input shape is (batch_size, sequence_length, input_size)\n",
        "input_shape = (13, 9)\n",
        "model = RecurrentModel()\n",
        "\n",
        "# Create a dummy input tensor for testing\n",
        "dummy_input = torch.randn(1, input_shape[0], input_shape[1])\n",
        "\n",
        "# Forward pass\n",
        "output = model(dummy_input)\n",
        "\n",
        "# Visualize the model\n",
        "dot = make_dot(output, params=dict(model.named_parameters()))\n",
        "dot.render(\"RecurrentModelVisualization\", format=\"png\", cleanup=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CY_74IX7TNOE",
        "outputId": "f791ad1a-e7e7-48ee-cbec-8c04af122d5b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RecurrentModelVisualization.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46NRSdJRTP4f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}